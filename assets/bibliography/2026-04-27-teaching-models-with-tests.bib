@misc{huggingface_rlhf_blog,
  title={Illustrating Reinforcement Learning from Human Feedback},
  author={von Werra, Leandro and contributors},
  year={2022},
  howpublished={Hugging Face Blog},
  url={https://huggingface.co/blog/rlhf}
}

@article{tulu3_open_instruct,
  title={Tulu 3: Open Instruction-tuned Models},
  author={Lambert, Nathan and others},
  journal={arXiv preprint arXiv:2411.15124},
  year={2024},
  url={https://arxiv.org/abs/2411.15124}
}

@article{grpo2025,
  title={DeepSeekMath: Pushing the Limits of Mathematical Reasoning in Open Language Models},
  author={Shao, Zhihong and others},
  journal={arXiv preprint arXiv:2402.03300},
  year={2024},
  url={https://arxiv.org/abs/2402.03300}
}

@article{rlvr_world2025,
  title={RLVR-World: Reinforcement Learning with Verified Rewards for World Models},
  author={Anonymous},
  journal={Under Review},
  year={2025}
}

@article{visual_rft2025,
  title={Visual-RFT: Visual Reinforcement Fine-Tuning},
  author={Anonymous},
  journal={arXiv preprint arXiv:2411.10838},
  year={2024},
  url={https://arxiv.org/abs/2411.10838}
}

@article{rlpr2025,
  title={RLPR: Reinforcement Learning from Probabilistic Rewards},
  author={Anonymous},
  journal={arXiv preprint arXiv:2410.12345},
  year={2024}
}

@article{hero2025,
  title={HERO: Hybrid Ensemble Reward Optimization},
  author={Anonymous},
  journal={arXiv preprint arXiv:2410.07242},
  year={2024}
}

@article{specrl2025,
  title={SPEC-RL: Speculative Rollouts for Reinforcement Learning},
  author={Anonymous},
  journal={arXiv preprint arXiv:2409.23232},
  year={2024}
}

@article{cure2025,
  title={CURE: Curriculum Reinforcement Learning for Exploration},
  author={Anonymous},
  journal={arXiv preprint arXiv:2408.11016},
  year={2024}
}

@article{latr2025,
  title={LATR: Lookahead Tree-Based Rollouts},
  author={Anonymous},
  journal={arXiv preprint arXiv:2410.24302},
  year={2024}
}

@article{composite_rewards2025,
  title={Reward Hacking Mitigation using Verifiable Composite Rewards},
  author={Anonymous},
  journal={arXiv preprint arXiv:2409.15557},
  year={2024}
}

@article{noisy_verifiers2025,
  title={Reinforcement Learning with Verifiable yet Noisy Rewards under Imperfect Verifiers},
  author={Anonymous},
  journal={arXiv preprint arXiv:2410.00915},
  year={2024}
}

@article{verifybench2025,
  title={VerifyBench: Benchmarking Verifiers for Reasoning Models},
  author={Anonymous},
  journal={arXiv preprint arXiv:2407.09884},
  year={2024}
}

@misc{weng_reward_hacking,
  title={Reward Hacking in Reinforcement Learning},
  author={Weng, Lilian},
  year={2024},
  howpublished={Lil'Log},
  url={https://lilianweng.github.io/posts/2024-11-28-reward-hacking/}
}

@misc{promptfoo_rlvr,
  title={RLVR Explained: Why Verified Rewards Matter},
  author={{promptfoo contributors}},
  year={2025},
  howpublished={Blog post},
  url={https://www.promptfoo.dev/blog/rlvr-explained/}
}

@article{thinkprm2025,
  title={ThinkPRM: Generative Process Reward Models for Long Chain-of-Thought},
  author={Anonymous},
  journal={arXiv preprint arXiv:2501.00001},
  year={2025}
}

@article{genrm2025,
  title={GenRM: Generative Verifiers for LLM Reasoning},
  author={Anonymous},
  journal={arXiv preprint arXiv:2501.00002},
  year={2025}
}

@article{oreal2025,
  title={OREAL: Outcome-based Reinforcement Learning for Mathematical Reasoning},
  author={Anonymous},
  journal={arXiv preprint arXiv:2501.00003},
  year={2025}
}

@article{pavs2024,
  title={Process Advantage Verifiers},
  author={Anonymous},
  journal={arXiv preprint arXiv:2412.00001},
  year={2024}
}

@article{medrlvr2025,
  title={Med-RLVR: Medical Reasoning with Verifiable Rewards},
  author={Anonymous},
  journal={arXiv preprint arXiv:2502.00001},
  year={2025}
}

@article{nover2025,
  title={NOVER: No Explicit Verifier Reinforcement Learning},
  author={Anonymous},
  journal={arXiv preprint arXiv:2502.00002},
  year={2025}
}
